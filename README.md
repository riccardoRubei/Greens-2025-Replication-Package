# Greens 2025
Replication Package for the paper: "Prompt engineering and its implications on the energy consumption of Large Language Models" submitted at 9th International Workshop on Green and Sustainable Software (GREENSâ€™25)

**Overview of the package**
- Analysis: This folder contains the scripts we used to perform the analysis (exact-match, edit-distance, average consumption, execution time).
- Experiments: This folder contains all the results we obtained from our study. See the next section for further details.
- GroundTruth: This folder contains the ground truth dataset we used to analyse the accuracy of the LLM. We generated it from the code-to-code test dataset of codeXGLUE.
- Snippets: This folder contains the scripts we used to query Llama3-Instruct.

**Description of the Experiments Folder**
- This folder contains our results obtained from the execution of the Llama3-Instruct inference. Since each sub-folder contains 15k files, we compressed the files.
- Answers: This folder contains all the answer we obtained from the study.
- CodeCarbon: This folder contains the resulst produced by CodeCarbon. Please refer to the official documentation of CodeCarbon for more details. https://mlco2.github.io/codecarbon/output.html
- Questions: This folder contains all the question in the string format we used to conduct the inference.

Each folder contains 5000 files: 1000 snippets x 5 custom configurations (conf0-conf4).

Inside a Question and Answer snippet there are 5 questions and answers (each inference has been repeated 5 times) separeted by strings like *>>>Start LLM Answer<<<* to help the user in a visual inspection.

The CodeCarbon contains the .csv files generated by CodeCarbon. Each file contains 5 rows (one per repeated inference test).
